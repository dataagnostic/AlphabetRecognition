{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-batman",
   "metadata": {},
   "source": [
    "## Demo Alphabet Recognition (Sign and Draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dimensional-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fifth-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "signs = ['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outdoor-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_hw = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "valid-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continuous-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmark_list(image, landmarks, mode = 0):\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_point = []\n",
    "\n",
    "    # Keypoint\n",
    "    for landmark in landmarks.landmark:\n",
    "        if mode == 0 :\n",
    "            landmark_x = landmark.x\n",
    "            landmark_y = landmark.y\n",
    "        # Denormalization\n",
    "        else:\n",
    "            landmark_x = int(landmark.x * image_width)\n",
    "            landmark_y = int(landmark.y * image_height)\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "    return landmark_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alike-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_landmark(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    # Convert to relative coordinates\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    # Convert to a one-dimensional list\n",
    "    temp_landmark_list = list(itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "powerful-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_less(lis, val):\n",
    "    return(all(val <= x[1] for x in lis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tight-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint(frame,points):\n",
    "    for i in range(len(points)):           \n",
    "        for j in range(1,len(points[i])): \n",
    "            cv2.line(frame, points[i][j - 1], points[i][j], (100, 0, 255), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bulgarian-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For webcam input:\n",
    "mode = 0 # starting mode (spacebar to change mode)\n",
    "m = ['Sign','Draw']\n",
    "cap = cv2.VideoCapture(0)\n",
    "mlp_model = load_model('model/model_hg_42.hdf5', compile=True )  # mode 0 for sign\n",
    "cnn_model = load_model('model/handwriting_bestmodel.hdf5') # mode 1 for draw\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.6,\n",
    "    max_num_hands=1,\n",
    "    min_tracking_confidence=0.6) as hands:\n",
    "    sen = ''\n",
    "    cf = []\n",
    "    rpoints = [[]]\n",
    "    clear =  0\n",
    "    cf_count = 0\n",
    "    while cap.isOpened():    \n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # Flip the image horizontally for a later selfie-view display, and convert\n",
    "        # the BGR image to RGB.\n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)        \n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        # Draw the hand annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)       \n",
    "        if results.multi_hand_landmarks:      \n",
    "            landmark_list = get_landmark_list(image,results.multi_hand_landmarks[0], mode)                          \n",
    "            # Sign mode\n",
    "            if mode == 0:\n",
    "                mp_drawing.draw_landmarks(image, results.multi_hand_landmarks[0], mp_hands.HAND_CONNECTIONS)\n",
    "                pre_processed_landmark_list = pre_process_landmark(landmark_list)\n",
    "                prediction = mlp_model.predict([pre_processed_landmark_list])                \n",
    "                result = signs[int(np.argmax(prediction))]\n",
    "                if not cf:\n",
    "                    cf.append(result)\n",
    "                elif result in cf:\n",
    "                    cf.append(result)\n",
    "                elif result not in cf:\n",
    "                    cf.clear()\n",
    "                if len(cf) > 50:\n",
    "                    if 'del' in cf:\n",
    "                        if sen:\n",
    "                            sen = sen[:-1]\n",
    "                    elif 'space'  in cf:\n",
    "                        sen += ' '\n",
    "                    else:\n",
    "                        sen += result   \n",
    "                    cf.clear()\n",
    "                    image = cv2.putText(image, 'Confirmed', \n",
    "                                    (280, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                                    (0, 255, 0),2,cv2.LINE_AA)\n",
    "                image = cv2.putText(image, result, \n",
    "                                    (190, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                                    (0, 0, 255),2,cv2.LINE_AA)\n",
    "            #Draw mode\n",
    "            elif mode == 1:   \n",
    "                draw_frame = np.zeros([image.shape[0],image.shape[1],1],dtype=np.uint8)\n",
    "                draw_frame.fill(255) \n",
    "                if (landmark_list[11][1] <= landmark_list[12][1] and landmark_list[15][1] <= landmark_list[16][1] and\n",
    "                    landmark_list[19][1] <= landmark_list[20][1] and landmark_list[7][1] > landmark_list[8][1] and \n",
    "                   check_less(landmark_list,landmark_list[8][1])):\n",
    "                    \n",
    "                    rpoints[-1].append((landmark_list[8][0], landmark_list[8][1]))\n",
    "                    cv2.circle(image, (landmark_list[8][0], landmark_list[8][1]), 3, (0, 0, 250), 12)\n",
    "                    clear = 0\n",
    "                    cf_count = 0\n",
    "                elif  check_less(landmark_list,landmark_list[4][1]) and rpoints[0] :                                        \n",
    "                    cf_count += 1\n",
    "                    if cf_count >= 30:                        \n",
    "                        paint(draw_frame, rpoints)\n",
    "                        # Convert to binary and change bg = black, fg = white\n",
    "                        draw_frame[draw_frame < 255] = 0\n",
    "                        draw_frame  = cv2.bitwise_not(draw_frame)\n",
    "        \n",
    "                        # Morph-op to remove noise\n",
    "                        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15,15))\n",
    "                        morphed = cv2.morphologyEx(draw_frame , cv2.MORPH_CLOSE, kernel)\n",
    "                        # Find the max-area contour\n",
    "                        cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "                        if cnts:                            \n",
    "                            cnt = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "                            # Get bounding box\n",
    "                            x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "                            # Crop image using bounding box \n",
    "                            dst = morphed[y-10:y+h+10, x-10:x+w+10]   \n",
    "\n",
    "                            # Preprocess input\n",
    "                            image_output = cv2.resize(dst, (28, 28))      \n",
    "                            image_output = np.array(image_output)\n",
    "                            image_output = image_output.astype('float32')/255\n",
    "                            # Model prediction\n",
    "                            prediction = cnn_model.predict(image_output.reshape(1,28,28,1))                    \n",
    "                            result = eng_hw[int(np.argmax(prediction))]\n",
    "                            sen += result\n",
    "                            rpoints.clear()\n",
    "                            rpoints.append([])\n",
    "                            clear = 0\n",
    "                            cf_count = 0\n",
    "                            image = cv2.putText(image, result, \n",
    "                                            (190, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                                            (0, 0, 255),2,cv2.LINE_AA)\n",
    "                            image = cv2.putText(image, 'Confirmed', \n",
    "                                            (280, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                                            (0, 255, 0),2,cv2.LINE_AA)                     \n",
    "                elif  landmark_list[4][1] > landmark_list[0][1]:\n",
    "                    clear += 1\n",
    "                    rpoints.clear()\n",
    "                    rpoints.append([])\n",
    "                    image = cv2.putText(image, 'Cleared', \n",
    "                                    (280, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                                    (0, 255, 0),2,cv2.LINE_AA)\n",
    "                    cf_count = 0\n",
    "                else:   \n",
    "                    clear = 0\n",
    "                    cf_count = 0\n",
    "                    cv2.circle(image, (landmark_list[8][0], landmark_list[8][1]), 3, (0, 250, 250), 12)\n",
    "                    if rpoints[-1] :                        \n",
    "                        rpoints.append([])\n",
    "            if clear > 30:\n",
    "                clear = 0\n",
    "                if sen:\n",
    "                    sen = sen[:-1]\n",
    "                    \n",
    "            paint(image,rpoints)  \n",
    "        image = cv2.putText(image, 'Prediction: ' , \n",
    "                                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                                (0, 0, 255),2,cv2.LINE_AA)\n",
    "        image = cv2.putText(image, 'Result: '+ sen, \n",
    "                    (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                    (0, 0, 255),2,cv2.LINE_AA)\n",
    "        image = cv2.putText(image, 'Mode: '+ m[mode], \n",
    "                                    (image.shape[1] - 190, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, \n",
    "                                    (0, 0, 255),2,cv2.LINE_AA)   \n",
    "                      \n",
    "\n",
    "        cv2.imshow('Alphabet Recognition (SPACEBAR to change mode | ESC to quit)', image)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if (key == 27):\n",
    "            break\n",
    "        elif (key == 32): # Spacebar\n",
    "            if mode == 0:\n",
    "                mode = 1\n",
    "                cf.clear()\n",
    "                sen =''\n",
    "            elif mode == 1:\n",
    "                mode = 0\n",
    "                rpoints.clear()\n",
    "                rpoints.append([])\n",
    "                sen = ''\n",
    "cv2.destroyAllWindows()     # close all OpenCV windows\n",
    "if cap.isOpened():\n",
    "    cap.release()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
